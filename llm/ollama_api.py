import json
import os
import time
import re
import traceback
import requests
from dotenv import load_dotenv


load_dotenv()  # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² ÙØ§ÛŒÙ„ .env

# ÙØ±Ø¶: ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ø¯Ø± Ø±ÛŒØ´Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
HISTORY_PATH = os.path.join(os.path.dirname(__file__), "..", "conversation.json")

def save_to_history(user_msg: str, assistant_msg: str):
    """Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ù…Ú©Ø§Ù„Ù…Ù‡ (Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡)"""
    try:
        history = []
        if os.path.exists(HISTORY_PATH):
            try:
                with open(HISTORY_PATH, "r", encoding="utf-8") as f:
                    # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø®Ø§Ù„ÛŒ ÛŒØ§ Ø®Ø±Ø§Ø¨ Ø¨ÙˆØ¯ØŒ Ø¨Ù‡ Ø¬Ø§ÛŒ Ø®Ø·Ø§ Ø¯Ø§Ø¯Ù†ØŒ history=[] Ù…ÛŒâ€ŒÚ¯Ø°Ø§Ø±ÛŒÙ…
                    try:
                        history = json.load(f)
                        if not isinstance(history, list):
                            history = []
                    except (json.JSONDecodeError, ValueError):
                        history = []
            except Exception:
                history = []

        history.append({"user": user_msg, "assistant": assistant_msg})

        # Ù†Ú¯Ù‡â€ŒØ¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 10 Ù…Ú©Ø§Ù„Ù…Ù‡ Ø¢Ø®Ø±
        if len(history) > 10:
            history = history[-10:]

        with open(HISTORY_PATH, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[OLLAMA] âŒ Ø®Ø·Ø§ Ø¯Ø± save_to_history: {e}")
        traceback.print_exc()

class OllamaAPI:
    def __init__(self):
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯Ùˆ Ù…Ø¯Ù„ Ù…Ø¬Ø²Ø§
        self.action_model = os.getenv("ACTION_MODEL_NAME", "phi4-mini:3.8b")
        self.chat_model = os.getenv("CHAT_MODEL_NAME", "dolphin3:latest")
        self.api_url = os.getenv("API_URL_CHAT", "http://localhost:11434/api/chat")
        # Ù„ÛŒØ³Øª Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡â€ŒÙ‡Ø§ Ùˆ Ú¯ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø­Ø§ÙˆØ±Ù‡â€ŒØ§ÛŒ (ÙØ§Ø±Ø³ÛŒ/Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ)
        self.tool_keywords = os.getenv("TOOL_KEYWORDS", "").split(",")
        # Ø±ÛŒØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ø³Ø±ÛŒØ¹ (fallback)
        self.verb_roots = os.getenv("VERB_ROOTS", "").split(",")

    def _normalize_for_keyword_search(self, text: str) -> str:
        # Ø­Ø°Ù Ø¹Ù„Ø§Ø¦Ù… Ù†Ú¯Ø§Ø±Ø´ÛŒ (ØºÛŒØ± Ø­Ø±Ù/Ø¹Ø¯Ø¯/Ø­Ø±ÙˆÙ ÙØ§Ø±Ø³ÛŒ)ØŒ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú© Ùˆ ÛŒÚ©â€ŒÚ©Ø³Ø±Ù‡ Ú©Ø±Ø¯Ù† ÙØ§ØµÙ„Ù‡â€ŒÙ‡Ø§
        t = text.lower()
        t = re.sub(r"[^\w\u0600-\u06FF]+", " ", t)
        t = re.sub(r"\s+", " ", t).strip()
        return f" {t} "

    def _detect_action(self, user_query: str) -> bool:
        """ØªØ´Ø®ÛŒØµ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø¨Ø²Ø§Ø±: ØªØ·Ø¨ÛŒÙ‚ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± ØªÙˆÚ©Ù† Ùˆ fallback Ø±ÛŒØ´Ù‡â€ŒØ§ÛŒ"""
        try:
            norm_q = self._normalize_for_keyword_search(user_query)
            tokens = [t for t in norm_q.split() if t]
            token_set = set(tokens)

            # 1) ØªØ·Ø¨ÛŒÙ‚ Ø¯Ù‚ÛŒÙ‚ ØªÙˆÚ©Ù†ÛŒ (Ù‡Ø± Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ Ú©Ù‡ Ù‡Ù…Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒØ´ Ø¯Ø± Ù¾Ø±Ø³Ø´ Ø¨Ø§Ø´Ø¯)
            for kw in self.tool_keywords:
                norm_kw = self._normalize_for_keyword_search(kw).strip()
                if not norm_kw:
                    continue
                kw_tokens = [t for t in norm_kw.split() if t]
                if not kw_tokens:
                    continue
                # Ø§Ú¯Ø± Ù‡Ù…Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ Ø¯Ø± ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø³Ø´ Ø¨Ø§Ø´Ù†Ø¯ => Ø§Ø¨Ø²Ø§Ø± Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø§Ø³Øª
                if all(tok in token_set for tok in kw_tokens):
                    print(f"[OLLAMA] _detect_action matched tokens for keyword: {kw}")
                    return True
                # Ù‡Ù…Ú†Ù†ÛŒÙ† Ø§Ú¯Ø± Ø¹Ø¨Ø§Ø±Øª Ú©Ù„ÛŒØ¯ÙˆØ§Ú˜Ù‡ Ø¨Ù‡â€ŒØ¹Ù†ÙˆØ§Ù† Ø²ÛŒØ±Ø±Ø´ØªÙ‡ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                if f" {norm_kw} " in norm_q:
                    print(f"[OLLAMA] _detect_action matched substring for keyword: {kw}")
                    return True

            # 2) fallback Ø³Ø§Ø¯Ù‡: Ø¨Ø±Ø±Ø³ÛŒ Ø±ÛŒØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ (Ø¨Ø±Ø§ÛŒ ØªÙ„ÙÛŒÙ‚â€ŒÙ‡Ø§ÛŒ ÙØ¹Ù„/ØµÙØª)
            for root in self.verb_roots:
                if f" {root} " in norm_q:
                    print(f"[OLLAMA] _detect_action matched root: {root}")
                    return True
                if root in norm_q:
                    return True

            return False
        except Exception as e:
            print(f"[OLLAMA] âŒ Ø®Ø·Ø§ Ø¯Ø± _detect_action: {e}")
            traceback.print_exc()
            return False

    def send_to_model(self, user_query: str) -> str:
        try:
            # ØªØ´Ø®ÛŒØµ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø¨Ø²Ø§Ø±
            is_action = self._detect_action(user_query)
            print(f"[OLLAMA] Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø§Ø¨Ø²Ø§Ø±: {is_action}")

            # Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ø¯Ù„ Ùˆ Ù¾Ø±Ø§Ù…Ù¾Øª Ø³ÛŒØ³ØªÙ…
            if is_action:
                model = self.action_model
                # Ù¾Ø±Ø§Ù…Ù¾Øª Ø³ÛŒØ³ØªÙ…: Ø§Ù†ØªØ¸Ø§Ø± JSON Ø¨Ø§ Ù†Ø§Ù… Ø§Ø¨Ø²Ø§Ø±
                system_content = (
                    """
                      "You have access to the following tools:\n"
                      "- script_executor: Generate and run a script. Arguments: {\"task\": \"string\", \"dry_run\": false}\n\n"
                      "Rules:\n"
                      "1. Return ONLY a JSON object with \"name\" and \"arguments\".\n"
                      "2. \"name\" MUST be exactly one of: \"create_file\" or \"script_executor\".\n"
                      "3. NEVER invent new tool names.\n"
                      "4. If unsure, use \"script_executor\" with the full user request as \"task\".\n"
                      "5. NO markdown, NO explanation, NO extra text.\n\n"
                      "Example:\n"
                      "{\"name\": \"script_executor\", \"arguments\": {\"task\": \"Create a folder named test on desktop\", \"dry_run\": true}}"

                    """.strip()
                )
            else:
                model = self.chat_model
                # Ù¾Ø±Ø§Ù…Ù¾Øª Ø³ÛŒØ³ØªÙ…: Ú¯ÙØªÚ¯ÙˆÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ
                # Ù¾Ø±Ø§Ù…Ù¾Øª Ø³ÛŒØ³ØªÙ…: Ú¯ÙØªÚ¯ÙˆÛŒ Ù…Ø¹Ù…ÙˆÙ„ÛŒ (Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ØŒ ÙØ§Ø±Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ø±Ø¨Ø±)
                system_content = """
                    You are Jack, a Persian-speaking AI assistant created by Hamidreza.  
                    You respond only in Persian, clearly and briefly â€” never in English.  
                    Your purpose is to help users with simple tasks and answer questions naturally.  
                    You can create folders, find files, and execute automated scripts upon request.  
                    Your name is Jack.  
                    You support both voice and text interactions.  
                    If asked who made you, say: "I was created by Hamidreza."  
                    If asked what you can do, say: "I can perform simple tasks like creating folders and finding files."  
                    If asked your name, say: "My name is Jack."  
                    If asked how to interact with you, say: "You can talk to me using voice or text."  
                    Always be helpful, polite, and concise. Never explain more than needed. Never use markdown, lists, or extra punctuation.
                    """.strip()
            # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ùˆ ØªØ§Ø±ÛŒØ®Ú†Ù‡
            messages = []
            history_text = ""
            if os.path.exists(HISTORY_PATH):
                try:
                    with open(HISTORY_PATH, "r", encoding="utf-8") as f:
                        try:
                            history = json.load(f)
                        except (json.JSONDecodeError, ValueError):
                            history = []
                        recent_history = history[-5:]
                        for item in recent_history:
                            history_text += f"ğŸ‘¤ User: {item.get('user','')}\nğŸ¤– Assistant: {item.get('assistant','')}\n\n"
                except Exception as e:
                    print(f"[OLLAMA] âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØ§Ø±ÛŒØ®Ú†Ù‡: {e}")
                    traceback.print_exc()

            if history_text.strip():
                messages.append({
                    "role": "user",
                    "content": f"ğŸ“ Previous conversation history:\n{history_text.strip()}"
                })

            messages.append({"role": "system", "content": system_content})
            messages.append({"role": "user", "content": user_query})

            # Ù¾Ø§ÛŒÙ‡ payload
            payload = {
                "model": model,
                "messages": messages,
                "stream": False,
                "options": {
                    "num_ctx": 2048,
                    "num_predict": 256
                }
            }

            # Ø§Ú¯Ø± Ø­Ø§Ù„Øª Ø§Ø¨Ø²Ø§Ø± Ø¨ÙˆØ¯ØŒ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ø±Ø§ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
            if is_action:
                try:
                    from .tool_selector import ToolSelector
                    tool_selector = ToolSelector()
                    relevant_tools = tool_selector.select_relevant_tools(user_query, top_k=3)
                    safe_tools = []
                    name_to_schema = {}
                    for t in relevant_tools:
                        if isinstance(t, dict) and "name" in t:
                            tool_entry = {
                                "name": t["name"],
                                "description": t.get("description", "")
                            }
                            if "parameters" in t and isinstance(t["parameters"], dict):
                                tool_entry["parameters"] = t["parameters"]
                                name_to_schema[t["name"]] = t["parameters"]
                            safe_tools.append(tool_entry)

                    if safe_tools:
                        payload["tools"] = safe_tools
                        print(f"[OLLAMA] âœ… Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ÛŒ: {[t['name'] for t in safe_tools]}")

                        # Ù„Ø§Ú¯ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§
                        try:
                            base_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
                            logs_dir = os.path.join(base_dir, "logs")
                            os.makedirs(logs_dir, exist_ok=True)
                            log_file = os.path.join(logs_dir, "tools_sent.log")
                            log_entry = {
                                "ts": time.strftime("%Y-%m-%d %H:%M:%S"),
                                "user_query": user_query,
                                "tools_sent": safe_tools
                            }
                            with open(log_file, "a", encoding="utf-8") as lf:
                                lf.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
                            print(f"[OLLAMA] âœ… Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ Ù„Ø§Ú¯ Ø´Ø¯Ù†Ø¯: {log_file}")
                        except Exception as e:
                            print(f"[OLLAMA] âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù„Ø§Ú¯ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§: {e}")
                            traceback.print_exc()
                    else:
                        print("[OLLAMA] âš ï¸ Ù‡ÛŒÚ† Ø§Ø¨Ø²Ø§Ø± Ù…Ø¹ØªØ¨Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")
                except Exception as e:
                    print(f"[OLLAMA] âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªØ®Ø§Ø¨ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§: {e}")
                    traceback.print_exc()

            # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù…Ø¯Ù„
            start_time = time.time()
            print("=================================")
            print(payload)
            print("==================================")
            response = requests.post(self.api_url, json=payload, timeout=300)
            response.raise_for_status()
            data = response.json()

            message = data.get("message", {})
            raw = message.get("content", "").strip()
            elapsed = time.time() - start_time
            print(f"[OLLAMA] ğŸ•’ Ø²Ù…Ø§Ù† Ù¾Ø§Ø³Ø®: {elapsed:.2f} Ø«Ø§Ù†ÛŒÙ‡")
            print(f"[OLLAMA] ğŸ“¤ Ù¾Ø§Ø³Ø® Ø®Ø§Ù…: {raw}")

            cleaned_raw = raw.replace("```json", "").replace("```", "").strip()

            # Ø§Ú¯Ø± Ø­Ø§Ù„Øª Ø§Ø¨Ø²Ø§Ø± Ø¨ÙˆØ¯: parse Ùˆ Ø§Ù†ØªØ¸Ø§Ø± {"name", "arguments"}
            if is_action:
                try:
                    parsed = json.loads(cleaned_raw)
                    if isinstance(parsed, dict) and "name" in parsed and "arguments" in parsed:
                        received_name = parsed["name"]
                        args = parsed.get("arguments", {})

                        # ØªØ¹ÛŒÛŒÙ† Ù†Ø§Ù… Ù†Ù‡Ø§ÛŒÛŒ Ø§Ø¨Ø²Ø§Ø± (Ù…Ø³ØªÙ‚ÛŒÙ… ÛŒØ§ ØªØµØ­ÛŒØ­â€ŒØ´Ø¯Ù‡)
                        final_tool_name = None
                        final_args = args

                        # Ù„ÛŒØ³Øª Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„ÛŒ (Ù†Ø§Ù… Ù…Ø¹ØªØ¨Ø±)
                        provided_tool_names = [t["name"] for t in safe_tools]

                        if received_name in provided_tool_names:
                            final_tool_name = received_name
                            schema = name_to_schema.get(received_name, {})
                            norm_args, _, missing = self._validate_and_normalize_arguments(schema, args)
                            if missing:
                                props = schema.get("properties", {}) if isinstance(schema, dict) else {}
                                for m in missing:
                                    p = props.get(m, {})
                                    norm_args[m] = "" if p.get("type") == "string" or not p.get("type") else 0
                            final_args = norm_args
                        else:
                            # ØªØµØ­ÛŒØ­ Ù†Ø§Ù… Ø¨Ø§ difflib
                            import difflib
                            candidate = difflib.get_close_matches(received_name, provided_tool_names, n=1, cutoff=0.6)
                            if candidate:
                                final_tool_name = candidate[0]
                                schema = name_to_schema.get(final_tool_name, {})
                                norm_args, _, missing = self._validate_and_normalize_arguments(schema, args)
                                if missing:
                                    props = schema.get("properties", {}) if isinstance(schema, dict) else {}
                                    for m in missing:
                                        p = props.get(m, {})
                                        norm_args[m] = "" if p.get("type") == "string" or not p.get("type") else 0
                                final_args = norm_args

                        # Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø± Ùˆ ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ§Ù… Ù†Ù‡Ø§ÛŒÛŒ
                        if final_tool_name:
                            try:
                                from .run_tools import execute_tool
                                exec_result = execute_tool(final_tool_name, final_args)

                                # ØªØ­Ù„ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ùˆ ØªÙˆÙ„ÛŒØ¯ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±Ù…Ø­ÙˆØ±
                                try:
                                    result_json = json.loads(exec_result)
                                    if result_json.get("status") == "success":
                                        user_message = "Ø§Ø¨Ø²Ø§Ø± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯."
                                    else:
                                        user_message = "Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø± Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯."
                                except json.JSONDecodeError:
                                    # Ø§Ú¯Ø± Ø®Ø±ÙˆØ¬ÛŒ JSON Ù†Ø¨ÙˆØ¯ØŒ ÙˆÙ„ÛŒ Ø§Ø¬Ø±Ø§ Ø´Ø¯ â†’ Ù…ÙˆÙÙ‚ÛŒØª
                                    user_message = "Ø§Ø¨Ø²Ø§Ø± Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø¬Ø±Ø§ Ø´Ø¯."

                                save_to_history(user_query, user_message)
                                return user_message

                            except Exception as e:
                                error_msg = "Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø± Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯."
                                save_to_history(user_query, error_msg)
                                return error_msg
                        else:
                            # Ù†Ø§Ù… Ø§Ø¨Ø²Ø§Ø± Ú©Ø§Ù…Ù„Ø§Ù‹ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª
                            error_msg = "Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø¨Ø²Ø§Ø± Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯."
                            save_to_history(user_query, error_msg)
                            return error_msg

                    else:
                        # Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„ ÙØ±Ù…Øª Ø§Ø¨Ø²Ø§Ø± Ø±Ø§ Ù†Ø¯Ø§Ø±Ø¯ â†’ Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ
                        save_to_history(user_query, cleaned_raw)
                        return cleaned_raw

                except (json.JSONDecodeError, ValueError):
                    # Ù…Ø¯Ù„ Ù¾Ø§Ø³Ø® Ù…ØªÙ†ÛŒ Ø¯Ø§Ø¯Ù‡ (Ù†Ù‡ JSON)
                    save_to_history(user_query, cleaned_raw)
                    return cleaned_raw
            else:
                # Ø­Ø§Ù„Øª Ù…Ø¹Ù…ÙˆÙ„ÛŒ (ØºÛŒØ± Ø§Ø¨Ø²Ø§Ø±)
                save_to_history(user_query, cleaned_raw)
                return cleaned_raw

        except Exception as e:
            error_msg = f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ù…Ø¯Ù„ ÛŒØ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø±Ø®ÙˆØ§Ø³Øª: {e}"
            print(f"[OLLAMA] {error_msg}")
            traceback.print_exc()
            return error_msg

    def _validate_and_normalize_arguments(self, tool_schema: dict, args: dict):
        """
        Ø¨Ø± Ø§Ø³Ø§Ø³ schema (Ù…Ø«Ù„ tools.json.parameters) Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ Ø±Ø§ ÙÛŒÙ„ØªØ± Ùˆ Ù†Ø±Ù…Ø§Ù„Ø§ÛŒØ² Ù…ÛŒâ€ŒÚ©Ù†Ø¯.
        Ø®Ø±ÙˆØ¬ÛŒ: (normalized_args: dict, corrections: list[(received_key, mapped_key_or_None)], missing_required: list)
        """
        try:
            if not isinstance(args, dict):
                return {}, [], list(tool_schema.get("required", [])) if schema else []

            props = tool_schema.get("properties", {}) if isinstance(tool_schema, dict) else {}
            allowed_keys = set(props.keys())
            required = set(tool_schema.get("required", [])) if isinstance(tool_schema, dict) else set()

            # Ø³Ø§Ø®Øª Ù†Ú¯Ø§Ø´Øª Ø³Ø§Ø¯Ù‡ Ø§Ø² lowercase -> canonical
            key_map = {k.lower(): k for k in allowed_keys}

            normalized = {}
            corrections = []

            for rk, rv in args.items():
                lk = re.sub(r"[^0-9a-zA-Z\u0600-\u06FF]", "", rk).lower()
                if lk in key_map:
                    canonical = key_map[lk]
                    normalized[canonical] = rv
                    if canonical != rk:
                        corrections.append((rk, canonical))
                else:
                    # Ø§Ù…ØªØ­Ø§Ù†Ù Ù†Ú¯Ø§Ø´ØªÙ Ø±Ø§ÛŒØ¬ (Ù…Ø«Ù„Ø§Ù‹ contenttype -> content)
                    for cand in allowed_keys:
                        if lk == re.sub(r"[^0-9a-zA-Z\u0600-\u06FF]", "", cand).lower():
                            normalized[cand] = rv
                            corrections.append((rk, cand))
                            break
                    else:
                        # Ú©Ù„ÛŒØ¯ Ù†Ø§Ø´Ù†Ø§Ø³ â€” Ø¯ÙˆØ± Ù…ÛŒâ€ŒØ±ÛŒØ²ÛŒÙ… Ø§Ù…Ø§ Ù„Ø§Ú¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
                        corrections.append((rk, None))

            missing = list(required - set(normalized.keys()))
            return normalized, corrections, missing
        except Exception as e:
            print(f"[OLLAMA] âš ï¸ Ø®Ø·Ø§ Ø¯Ø± validate arguments: {e}")
            traceback.print_exc()
            return {}, [], list(tool_schema.get("required", [])) if tool_schema else []
