# project/ui/gui.py
import sys
from speech.tts import text_to_speech  # â† Ø¬Ø¯ÛŒØ¯


from PyQt6.QtWidgets import (
    QApplication, QMainWindow, QWidget, QVBoxLayout, QHBoxLayout,
    QTextEdit, QLineEdit, QPushButton, QStackedWidget
)
from PyQt6.QtCore import Qt, pyqtSignal, QObject
from PyQt6.QtGui import QFont

from llm.ollama_api import OllamaAPI
from speech import VADRecorder, audio_data_to_text

import threading

class Communicator(QObject):
    transcription_ready = pyqtSignal(str)
    model_response_ready = pyqtSignal(str)


class AssistantGUI(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ")
        self.resize(800, 600)

        QApplication.setLayoutDirection(Qt.LayoutDirection.RightToLeft)

        font = QFont("Vazirmatn", 12)
        if not font.exactMatch():
            font = QFont("B Nazanin", 12)
        self.setFont(font)

        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)

        # === Ú©Ø§Ø¯Ø± Ú†Øª: Ù…ØªÙ† Ø³ÛŒØ§Ù‡ØŒ Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ø³ÙÛŒØ¯ ===
        self.chat_display = QTextEdit()
        self.chat_display.setReadOnly(True)
        self.chat_display.setStyleSheet("""
            QTextEdit {
                background-color: white;
                color: black;
                font-size: 14px;
                padding: 10px;
                border: 1px solid #ccc;
            }
        """)
        main_layout.addWidget(self.chat_display, stretch=1)

        # === StackedWidget Ø¨Ø±Ø§ÛŒ Ø³ÙˆØ¦ÛŒÚ† Ø¨ÛŒÙ† Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ ===
        self.input_area = QStackedWidget()
        main_layout.addWidget(self.input_area)

        # --- Ø­Ø§Ù„Øª Ù…ØªÙ†ÛŒ ---
        self.text_widget = QWidget()
        text_layout = QHBoxLayout(self.text_widget)

        self.input_field = QLineEdit()
        self.input_field.setPlaceholderText("Ù¾ÛŒØ§Ù… Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯...")
        self.input_field.returnPressed.connect(self.send_text_message)
        text_layout.addWidget(self.input_field)

        self.send_button = QPushButton("â¤")
        self.send_button.setFixedWidth(50)
        self.send_button.setStyleSheet("""
            QPushButton {
                background-color: #2196F3;
                color: white;
                font-size: 18px;
                font-weight: bold;
                border: none;
            }
            QPushButton:hover {
                background-color: #1976D2;
            }
        """)
        self.send_button.clicked.connect(self.send_text_message)
        text_layout.addWidget(self.send_button)

        self.mic_button = QPushButton("ğŸ¤")
        self.mic_button.setFixedWidth(40)
        self.mic_button.setStyleSheet("font-size: 16px;")
        self.mic_button.clicked.connect(self.switch_to_voice_mode)
        text_layout.addWidget(self.mic_button)

        # --- Ø­Ø§Ù„Øª ØµÙˆØªÛŒ (Ø¨Ø¯ÙˆÙ† SVG) ---
        self.voice_widget = QWidget()
        voice_layout = QHBoxLayout(self.voice_widget)

        self.listen_button = QPushButton("â–¶ï¸ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù†")
        self.listen_button.clicked.connect(self.resume_listening)
        voice_layout.addWidget(self.listen_button)

        self.stop_button = QPushButton("â¹ ØªÙˆÙ‚Ù")
        self.stop_button.clicked.connect(self.stop_voice_listening)
        voice_layout.addWidget(self.stop_button)

        self.back_button = QPushButton("â† Ø¨Ø§Ø²Ú¯Ø´Øª Ø¨Ù‡ Ù…ØªÙ†")
        self.back_button.clicked.connect(self.switch_to_text_mode)
        voice_layout.addWidget(self.back_button)

        self.input_area.addWidget(self.text_widget)   # index 0
        self.input_area.addWidget(self.voice_widget)  # index 1

        # Ù…Ø§Ú˜ÙˆÙ„â€ŒÙ‡Ø§
        self.ollama_api = OllamaAPI()
        self.vad_recorder = None
        self.is_listening_vad = False
        self.communicator = Communicator()
        self.communicator.transcription_ready.connect(self.handle_transcription)
        self.communicator.model_response_ready.connect(self.display_model_response)

        self.waiting_for_response = False

    # ==================== Ù…Ø¯ÛŒØ±ÛŒØª Ø­Ø§Ù„Øªâ€ŒÙ‡Ø§ ====================

    def switch_to_voice_mode(self):
        self.input_area.setCurrentIndex(1)
        self.chat_display.append("<i>Ø­Ø§Ù„Øª ØµÙˆØªÛŒ ÙØ¹Ø§Ù„ Ø´Ø¯.</i>")
        self.scroll_to_bottom()
        self.start_continuous_listening()

    def switch_to_text_mode(self):
        self.stop_voice_listening()
        self.input_area.setCurrentIndex(0)
        self.input_field.setFocus()
        self.chat_display.append("<i>Ø­Ø§Ù„Øª Ù…ØªÙ†ÛŒ ÙØ¹Ø§Ù„ Ø´Ø¯.</i>")
        self.scroll_to_bottom()

    def start_continuous_listening(self):
        if not self.is_listening_vad:
            self.is_listening_vad = True
            self.vad_recorder = VADRecorder(
                on_speech_end=self._on_speech_recorded,
                silence_duration=1.0
            )
            self.vad_recorder.start_continuous()
            print("[GUI] Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† Ù¾ÛŒÙˆØ³ØªÙ‡ Ø´Ø±ÙˆØ¹ Ø´Ø¯.")

    def resume_listening(self):
        self.start_continuous_listening()
        self.chat_display.append("<i>Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† Ø§Ø² Ø³Ø± Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.</i>")
        self.scroll_to_bottom()

    def stop_voice_listening(self):
        if self.vad_recorder:
            self.vad_recorder.stop()
        self.is_listening_vad = False
        self.chat_display.append("<i>Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† Ù…ØªÙˆÙ‚Ù Ø´Ø¯.</i>")
        self.scroll_to_bottom()
        print("[GUI] Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù† Ù…ØªÙˆÙ‚Ù Ø´Ø¯.")

    # ==================== Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµØ¯Ø§ Ùˆ Ù…Ø¯Ù„ ====================
    
    def _on_speech_recorded(self, audio_data: bytes, sample_rate: int):
        print(f"[GUI] ØµØ¯Ø§ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ ({len(audio_data)} Ø¨Ø§ÛŒØª). Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ù…ØªÙ†...")
        text = audio_data_to_text(audio_data, sample_rate, language="fa-IR")
        self.communicator.transcription_ready.emit(text)

    def handle_transcription(self, text: str):
        """Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¯Ø±ÛŒØ§ÙØªÛŒ Ø§Ø² STT (Ø­Ø§Ù„Øª ØµÙˆØªÛŒ)"""
        if not text or not text.strip():
            print("[GUI] Ù…ØªÙ† Ø®Ø§Ù„ÛŒ Ø§Ø³Øª. Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´Ø¯.")
            return

        # 1. Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        self.chat_display.append(f"<b>Ø´Ù…Ø§ (ØµÙˆØªÛŒ):</b> {text}")
        self.scroll_to_bottom()

        # 2. Ù†Ù…Ø§ÛŒØ´ Ù¾ÛŒØ§Ù… Ø§Ù†ØªØ¸Ø§Ø±
        self.chat_display.append("<i>Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„...</i>")
        self.waiting_for_response = True
        self.send_button.setEnabled(False)
        self.scroll_to_bottom()

        # 3. Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù…Ø¯Ù„ Ø¯Ø± Thread Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
        threading.Thread(target=self._request_model_and_emit, args=(text,), daemon=True).start()

    def send_text_message(self):
        text = self.input_field.text().strip()
        if not text:
            return

        # Ù†Ù…Ø§ÛŒØ´ ÙÙˆØ±ÛŒ Ù¾ÛŒØ§Ù… Ú©Ø§Ø±Ø¨Ø±
        self.chat_display.append(f"<b>Ø´Ù…Ø§:</b> {text}")
        self.input_field.clear()
        self.scroll_to_bottom()  # âœ… Ø§Ø³Ú©Ø±ÙˆÙ„ Ù‚Ø¨Ù„ Ø§Ø² Ø§Ø±Ø³Ø§Ù„

        # Ø³Ù¾Ø³ Ù¾ÛŒØ§Ù… Ø§Ù†ØªØ¸Ø§Ø±
        self.chat_display.append("<i>Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„...</i>")
        self.waiting_for_response = True
        self.send_button.setEnabled(False)
        self.scroll_to_bottom()

        # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ Ù…Ø¯Ù„ Ø¯Ø± Thread Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
        threading.Thread(target=self._request_model_and_emit, args=(text,), daemon=True).start()

    def _request_model_and_emit(self, text: str):
        """ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ send_to_model Ø¯Ø± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ Ù†ØªÛŒØ¬Ù‡"""
        try:
            response = self.ollama_api.send_to_model(text)
        except Exception as e:
            response = f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ±Ø§Ø®ÙˆØ§Ù†ÛŒ Ù…Ø¯Ù„: {e}"
        # Ø§Ù†ØªØ´Ø§Ø± Ù†ØªÛŒØ¬Ù‡ Ø¨Ù‡ thread Ø§ØµÙ„ÛŒ
        self.communicator.model_response_ready.emit(response)

    def display_model_response(self, response: str):
        """Ù†Ù…Ø§ÛŒØ´ Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„ Ùˆ Ù¾Ø®Ø´ ØµØ¯Ø§ Ø¯Ø± Ø­Ø§Ù„Øª ØµÙˆØªÛŒ"""
        if self.waiting_for_response:
            current = self.chat_display.toPlainText()
            lines = current.split('\n')
            if lines and "Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± Ù¾Ø§Ø³Ø® Ù…Ø¯Ù„..." in lines[-1]:
                lines = lines[:-1]
                self.chat_display.setPlainText('\n'.join(lines))
            self.waiting_for_response = False

        self.send_button.setEnabled(True)
        self.chat_display.append(f"<b>Ø¯Ø³ØªÛŒØ§Ø±:</b> {response}")
        self.scroll_to_bottom()

        # âœ… Ù¾Ø®Ø´ ØµØ¯Ø§ ÙÙ‚Ø· Ø¯Ø± Ø­Ø§Ù„Øª ØµÙˆØªÛŒ
        if self.input_area.currentIndex() == 1:  # index 1 = Ø­Ø§Ù„Øª ØµÙˆØªÛŒ
            text_to_speech(response)




    # ==================== Ú©Ù…Ú©ÛŒ ====================

    def scroll_to_bottom(self):
        sb = self.chat_display.verticalScrollBar()
        sb.setValue(sb.maximum())